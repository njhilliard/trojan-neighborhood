{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbook for studying dark matter phase space in a specific snapshot from Elena's Trojans paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:44:52.798668Z",
     "iopub.status.busy": "2020-01-14T03:44:52.797972Z",
     "iopub.status.idle": "2020-01-14T03:44:53.239045Z",
     "shell.execute_reply": "2020-01-14T03:44:53.238408Z",
     "shell.execute_reply.started": "2020-01-14T03:44:52.798542Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:45:03.783138Z",
     "iopub.status.busy": "2020-01-14T03:45:03.782407Z",
     "iopub.status.idle": "2020-01-14T03:45:03.794024Z",
     "shell.execute_reply": "2020-01-14T03:45:03.792544Z",
     "shell.execute_reply.started": "2020-01-14T03:45:03.783010Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pylab\n",
    "import struct\n",
    "import matplotlib.cm as cm\n",
    "import conversions as co\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "#import tables as tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "* Hook up hdf5 to PyTables: save df to hdf5, figure out interfacing\n",
    "* Absolute color scaling - requires the range of all plots in one draw\n",
    "* Surface density plots should have the same x,y scale and orientations\n",
    "* Want each 2D histogram to have accompanying 1D histograms along col and row\n",
    "\n",
    "#### Aspirations:\n",
    "* Wrap the hdf5 reader such that it can read in chunks at a time (solved by PyTables)\n",
    "* ~~Or hook up to a database and use SQL~~ Hdf5 -> SQL is hilariously slow\n",
    "\n",
    "#### Notes:\n",
    "* snap hdf5 structure: f has keys 'Header', 'PartType1,2,3'\n",
    "* PartTypes have no attrs, keys = \"Coordinates\", \"ParticleIDs\", \"Velocities\" with no attrs\n",
    "    * Coords and Vels are ndarrays len == 3\n",
    "    * PT1=DM (20mil x 3), PT2=disk (8mil x 3), PT3=bulge (2.8mil x 3)\n",
    "* header has attributes with value == 0: \n",
    "    * BoxSize, OmegaLambda, Redshift\n",
    "    * Flag_[Cooling, DoublePrecision, Feedback, IC_Info, Metals, Sfr, StellarAge]\n",
    "* nonzero attrs: \n",
    "    * HubbleParam, Omega0 == 1, Time (in years / 10^9 (????))\n",
    "    * NumPart_ThisFile == NumPart_Total (array len 6), MassTable (array len 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:45:06.927803Z",
     "iopub.status.busy": "2020-01-14T03:45:06.927443Z",
     "iopub.status.idle": "2020-01-14T03:45:06.947656Z",
     "shell.execute_reply": "2020-01-14T03:45:06.946887Z",
     "shell.execute_reply.started": "2020-01-14T03:45:06.927749Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_hdf5(path, p_type=1):\n",
    "    \"\"\"types: 1=DM, 2=disk, 3=bulge\"\"\"\n",
    "    groups = [\"Header\", \"PartType1\", \"PartType2\", \"PartType3\"]\n",
    "    head = {}\n",
    "    \n",
    "    f = h5py.File(path, \"r\")\n",
    "    h = f[\"Header\"]\n",
    "    keys = list(h.attrs)\n",
    "    for key in keys:\n",
    "        head[key] = h.attrs[key]\n",
    "    parts = f[groups[p_type]]\n",
    "    columns = [\"x\",\"y\",\"z\", \"vx\", \"vy\", \"vz\"]\n",
    "    df = pd.DataFrame(\n",
    "        np.concatenate((parts[\"Coordinates\"], parts[\"Velocities\"]), axis=1), \n",
    "            columns=columns, index=parts[\"ParticleIDs\"][:])\n",
    "    df.index.name = \"particleID\"\n",
    "    f.close()\n",
    "    \n",
    "    return head, df\n",
    "\n",
    "def df_center(df):\n",
    "    \"\"\"Centers a data frame's x,y,z keys by subtracting the median.\"\"\"\n",
    "    idxs = ['x', 'y', 'z']\n",
    "    for idx in idxs:\n",
    "        df[idx] -= df[idx].median()\n",
    "        \n",
    "def df_polar(df):\n",
    "    \"\"\"Adds in r and phi coordinates, as well as their velocities.\n",
    "    Phi is the physics spherical phi, i.e. the polar theta.\n",
    "    \"\"\"\n",
    "    df['r'] = np.sqrt(df['x']**2 + df['y']**2)\n",
    "    df['phi'] = np.arctan2(df['y'], df['x'])\n",
    "    df['vr'] = (df['x']*df['vx'] + df['y']*df['vy']) / df['r']\n",
    "    df['vphi'] = (df['x']*df['vy'] - df['y']*df['vx']) / (df['r']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:45:07.113706Z",
     "iopub.status.busy": "2020-01-14T03:45:07.112982Z",
     "iopub.status.idle": "2020-01-14T03:45:07.130005Z",
     "shell.execute_reply": "2020-01-14T03:45:07.128949Z",
     "shell.execute_reply.started": "2020-01-14T03:45:07.113594Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_filter(df, key, low=None, high=None, f=None):\n",
    "    \"\"\"Filters a dataframe by key, greater than low, less than high,\n",
    "    optionally applying function f to the data comparison.\n",
    "    \"\"\"\n",
    "    if low is None and high is None:\n",
    "        print(\"No filtering done\")\n",
    "        return df\n",
    "    elif low is not None and high is not None:\n",
    "        if f is None:\n",
    "            return df[(df[key] > low) & (df[key] < high)]\n",
    "        else:\n",
    "            return df[(f(df[key]) > low) & (f(df[key]) < high)]\n",
    "    elif low is not None:\n",
    "        if f is None:\n",
    "            return df[df[key] > low]\n",
    "        else:\n",
    "            return df[f(df[key]) > low]\n",
    "    elif high is not None:\n",
    "        if f is None:\n",
    "            return df[df[key] < high]\n",
    "        else:\n",
    "            return df[f(df[key]) < high]\n",
    "    else:\n",
    "        print(\"Nani?\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:45:07.238339Z",
     "iopub.status.busy": "2020-01-14T03:45:07.238089Z",
     "iopub.status.idle": "2020-01-14T03:45:07.251951Z",
     "shell.execute_reply": "2020-01-14T03:45:07.251185Z",
     "shell.execute_reply.started": "2020-01-14T03:45:07.238301Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cuts(df, ztup, rtup, phitup,\n",
    "              bins=[100,100], vels=None, save=False, path='analysis/'):\n",
    "    \"\"\"NOTE: phi values from the tuple will be in degrees.\n",
    "    vels is a string of comma separated velocity keys (from the dataframe)\n",
    "    to be plotted, x vs y, for example, 'vphi, vr' or 'vphi, vz'.\n",
    "    \"\"\"\n",
    "    zlow, zhigh = ztup\n",
    "    rlow, rhigh = rtup\n",
    "    philow, phihigh = phitup\n",
    "    dff = df_filter(df, 'z', low=zlow, high=zhigh)\n",
    "    dff = df_filter(dff, 'r', low=rlow, high=rhigh)\n",
    "    dff = df_filter(dff, 'phi', low=philow*np.pi/180, high=phihigh*np.pi/180)\n",
    "    ti_tup = (zlow, zhigh, rlow, rhigh, philow, phihigh)\n",
    "    s = \"Snap cut between Z:{}-{}kpc, R:{}-{}kpc, PHI={}-{} degrees\"\n",
    "    title = s.format(*ti_tup)\n",
    "    fig = plt.figure()\n",
    "    plt.title(title)\n",
    "    if vels is None: #plot positions\n",
    "        plt.xlabel('X distance (kpc)')\n",
    "        plt.ylabel('Y distance (kpc)')\n",
    "        plt.hist2d(dff['x'], dff['y'], bins=bins, density=True)\n",
    "        pathadd = 'surfacedensity_'\n",
    "        if save:\n",
    "            end = \"Z{}-{}_R{}-{}_PH{}-{}\".format(*ti_tup)\n",
    "            plt.savefig(path + pathadd + end + \".png\", dpi=300)\n",
    "    elif vels is not None: #plot kinematics\n",
    "        assert type(vels) is str\n",
    "        keys = [v.strip() for v in vels.split(',')]\n",
    "        plt.xlabel('{} (km/s)'.format(keys[0]))\n",
    "        plt.ylabel('{} (km/s)'.format(keys[1]))\n",
    "        plt.hist2d(dff[keys[0]], dff[keys[1]], bins=bins, density=True)\n",
    "        pathadd = 'kinematics_'\n",
    "        if save:\n",
    "            end = \"Z{}-{}_R{}-{}_PH{}-{}\".format(*ti_tup)\n",
    "            plt.savefig(path + pathadd + keys[0] + keys[1]\n",
    "                        + '_' + end + \".png\",\n",
    "                        dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:45:07.379194Z",
     "iopub.status.busy": "2020-01-14T03:45:07.378941Z",
     "iopub.status.idle": "2020-01-14T03:45:07.401769Z",
     "shell.execute_reply": "2020-01-14T03:45:07.400863Z",
     "shell.execute_reply.started": "2020-01-14T03:45:07.379156Z"
    }
   },
   "outputs": [],
   "source": [
    "def multiplot_cuts(df, ztup_l, rtup_l, phitup_l,\n",
    "                   bins=[100,100], vels=None, save=False, path='analysis/',\n",
    "                   dim1=False):\n",
    "    \"\"\"Similar to previous plot_cuts but with one subplots per z slice.\n",
    "    NOTE: phi values from the tuple will be in degrees.\n",
    "    vels is a string of comma separated velocity keys\n",
    "    (from the dataframe) to be plotted, x vs y,\n",
    "    for example, 'vphi, vr' or 'vphi, vz'.\n",
    "    \"\"\"\n",
    "    for i in range(len(ztup_l)):\n",
    "        zlow, zhigh = ztup_l[i]\n",
    "        # figw, figh adjust plot size according to subplot dimensions:\n",
    "        figw, figh = 6.4*len(phitup_l), 4.8*len(rtup_l)\n",
    "        fig, ax = plt.subplots(len(rtup_l), len(phitup_l), \n",
    "                               figsize=[figw,figh], squeeze=False)\n",
    "        # save_tup is used for later save file name.\n",
    "        save_tup = (ztup_l[i][0], ztup_l[i][1], rtup_l[0][0], rtup_l[-1][1],\n",
    "                    phitup_l[0][0], phitup_l[-1][1])\n",
    "        if vels is None:\n",
    "            # TODO: have one X and Y axis title label\n",
    "            #fig.xlabel('X distance (kpc)')\n",
    "            #fig.ylabel('Y distance (kpc)')\n",
    "            pathadd = 'surfacedensity_'\n",
    "        elif vels is not None:\n",
    "            assert type(vels) is str\n",
    "            keys = [v.strip() for v in vels.split(',')]\n",
    "            # TODO: have one X and Y axis title label\n",
    "            #fig.xlabel('{} (km/s)'.format(keys[0]))\n",
    "            #fig.ylabel('{} (km/s)'.format(keys[1]))\n",
    "            pathadd = 'kinematics_'\n",
    "        \n",
    "        for j in range(len(rtup_l)):\n",
    "            rlow, rhigh = rtup_l[j]\n",
    "            \n",
    "            for k in range(len(phitup_l)):\n",
    "                philow, phihigh = phitup_l[k]\n",
    "                dff = df_filter(df, 'z', low=zlow, high=zhigh)\n",
    "                dff = df_filter(dff, 'r', low=rlow, high=rhigh)\n",
    "                dff = df_filter(dff, 'phi',\n",
    "                    low=philow*np.pi/180, high=phihigh*np.pi/180)\n",
    "                ti_tup = (zlow, zhigh, rlow, rhigh, philow, phihigh)\n",
    "                title = \"Z:{}-{}kpc, R:{}-{}kpc, PHI={}-{}deg\".format(*ti_tup)\n",
    "                ax[j,k].set_title(title)\n",
    "                if vels is None:   # Plot positions\n",
    "                    ax[j,k].set_xlabel('X distance (kpc)')\n",
    "                    ax[j,k].set_ylabel('Y distance (kpc)')\n",
    "                    if dim1:\n",
    "                        continue\n",
    "                        #TODO: fix\n",
    "                        #ax[j,k].hist(dff['x'], dff['y'],\n",
    "                                       #bins=bins)\n",
    "                    elif not dim1:\n",
    "                        ax[j,k].hist2d(dff['x'], dff['y'],\n",
    "                                       bins=bins, density=True)\n",
    "                elif vels is not None:   # Plot kinematics instead\n",
    "                    ax[j,k].set_xlabel('{} (km/s)'.format(keys[0]))\n",
    "                    ax[j,k].set_ylabel('{} (km/s)'.format(keys[1]))\n",
    "                    if dim1:\n",
    "                        continue\n",
    "                        #TODO: fix\n",
    "                        #ax[j,k].hist(dff[keys[0]],\n",
    "                                       #bins=bins)\n",
    "                    elif not dim1:\n",
    "                        ax[j,k].hist2d(dff[keys[0]], dff[keys[1]],\n",
    "                                       bins=bins[0], density=True)\n",
    "                    \n",
    "        #Back to outer z loop.\n",
    "        fig.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "        if save and vels is None:\n",
    "            end = \"Z{}-{}_R{}-{}_PH{}-{}\".format(*save_tup)\n",
    "            name = path + pathadd + end + \".png\"\n",
    "            print('saving file: ' + name)\n",
    "            fig.savefig(name, dpi=300)\n",
    "        elif save and vels is not None:\n",
    "            end = \"Z{}-{}_R{}-{}_PH{}-{}\".format(*save_tup)\n",
    "            name = path + pathadd + keys[0] + keys[1] + '_' + end + \".png\"\n",
    "            print('saving file: ' + name)\n",
    "            fig.savefig(name, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:45:07.772318Z",
     "iopub.status.busy": "2020-01-14T03:45:07.771572Z",
     "iopub.status.idle": "2020-01-14T03:45:07.794830Z",
     "shell.execute_reply": "2020-01-14T03:45:07.793812Z",
     "shell.execute_reply.started": "2020-01-14T03:45:07.772192Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_plots(df, *tups,\n",
    "              vels=None, path=\"analysis/\", multi=True, plot=True,\n",
    "              save=True, bins=[100,100], dim1=False):\n",
    "    \"\"\"Generates plots using either the above plot_cuts or multiplots\n",
    "    function with the given dataframe and tuples for a given coordinate\n",
    "    with (start, stop, step, key) as input tuples.\n",
    "    \"\"\"\n",
    "    assert df is not None\n",
    "    params = {'z':[(-10,10)], 'r':[(0,15)], 'phi':[(-180,180)]}\n",
    "    #default values^^\n",
    "    for tup in tups:\n",
    "        start, stop, step, key = tup\n",
    "        lst = []\n",
    "        while start < stop:\n",
    "            if start + step > stop:\n",
    "                lst.append((start, stop))\n",
    "                break\n",
    "            lst.append((start, start+step))\n",
    "            start += step\n",
    "        params[key] = lst\n",
    "    if plot:\n",
    "        print('starting plotting')\n",
    "        if multi:\n",
    "            multiplot_cuts(df, params['z'], params['r'], params['phi'],\n",
    "                           vels=vels, save=save, path=path, bins=bins,\n",
    "                           dim1=dim1)\n",
    "        elif not multi:\n",
    "            for z in params['z']:\n",
    "                for r in params['r']:\n",
    "                    for phi in params['phi']:\n",
    "                        print('.', end='')\n",
    "                        plot_cuts(df, z, r, phi,\n",
    "                            vels=vels, save=save, path=path, bins=bins)\n",
    "        print('done')\n",
    "        return None\n",
    "    elif not plot:\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:45:09.445887Z",
     "iopub.status.busy": "2020-01-14T03:45:09.445157Z",
     "iopub.status.idle": "2020-01-14T03:45:13.520279Z",
     "shell.execute_reply": "2020-01-14T03:45:13.519508Z",
     "shell.execute_reply.started": "2020-01-14T03:45:09.445760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Runs data reading and cleaning.\n",
    "path = \"data/snap_582.hdf5\"\n",
    "head, df = read_hdf5(path, p_type=1)\n",
    "df_center(df)\n",
    "df_polar(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:37:48.995146Z",
     "iopub.status.busy": "2020-01-14T03:37:48.994891Z",
     "iopub.status.idle": "2020-01-14T03:37:48.998250Z",
     "shell.execute_reply": "2020-01-14T03:37:48.997379Z",
     "shell.execute_reply.started": "2020-01-14T03:37:48.995096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to clean data\n",
    "# store = pd.HDFStore('data/cleaned.h5')\n",
    "# store.append('darkmatter', df, data_columns=True) #used to save the df to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-01-14T03:45:30.308739Z",
     "iopub.status.busy": "2020-01-14T03:45:30.308037Z",
     "iopub.status.idle": "2020-01-14T03:48:15.415980Z",
     "shell.execute_reply": "2020-01-14T03:48:15.411692Z",
     "shell.execute_reply.started": "2020-01-14T03:45:30.308628Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "insert expected 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-158bcc7c100f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/particles.db\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"darkmatter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2700\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2702\u001b[0;31m         sql.to_sql(\n\u001b[0m\u001b[1;32m   2703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    507\u001b[0m         )\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     pandas_sql.to_sql(\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1748\u001b[0m         )\n\u001b[1;32m   1749\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                 \u001b[0mchunk_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mexec_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     def _query_iterator(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_execute_insert_multi\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[1;32m    679\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minsert_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: insert expected 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"data/particles.db\")\n",
    "df.to_sql(\"darkmatter\", conn, method='multi', chunksize=1000, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2019-11-22T15:08:11.949915Z",
     "iopub.status.busy": "2020-01-13T15:48:29.197712Z",
     "iopub.status.idle": "2020-01-13T15:48:29.199057Z",
     "shell.execute_reply": "2019-11-22T15:08:43.242154Z",
     "shell.execute_reply.started": "2019-11-22T15:08:11.949853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generates multiplots of surface density and kinematics.\n",
    "#switch back to proper vels later\n",
    "for vels in ['vphi, vr', 'vr, vphi', 'vz, vr']:\n",
    "    gen_plots(df, (0, 6, 2, \"z\"), (4.5, 7.5, 1, 'r'), (0, 90, 30, 'phi'),\n",
    "              save=False, path='analysis/multis/', vels=vels, dim1=True)\n",
    "#gen_plots(df, (0, 6, 2, \"z\"), (4.5, 7.5, 1, 'r'), (60, 90, 30, 'phi'), path='analysis/multis/', save=False)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2019-11-22T14:16:34.224095Z",
     "iopub.status.busy": "2020-01-13T15:48:29.202454Z",
     "iopub.status.idle": "2020-01-13T15:48:29.204110Z",
     "shell.execute_reply": "2019-11-22T14:16:34.226137Z",
     "shell.execute_reply.started": "2019-11-22T14:16:34.224065Z"
    }
   },
   "outputs": [],
   "source": [
    "# An example single plot call.\n",
    "# plot_cuts((0,2), (5.5,6.5), (0,360), df, vels=\"vphi,vr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL too slow.\n",
    "#conn = sqlite3.connect('snap_582.db')\n",
    "#df.to_sql(\"dark_matter\", conn, if_exists=\"replace\", index=False)\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elena's original plotting code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2019-11-22T14:16:34.227594Z",
     "iopub.status.busy": "2020-01-13T15:48:29.209747Z",
     "iopub.status.idle": "2020-01-13T15:48:29.211789Z",
     "shell.execute_reply": "2019-11-22T14:16:34.244322Z",
     "shell.execute_reply.started": "2019-11-22T14:16:34.227565Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    path = \"data/snap_582.hdf5\"\n",
    "    head, df = read_hdf5(path, p_type=3) #testing with fewer particles\n",
    "    df[\"x\"] = df[\"x\"] - df[\"x\"].median()\n",
    "    df[\"y\"] = df[\"y\"] - df[\"y\"].median()\n",
    "    mass = head[\"MassTable\"][3]\n",
    "    BINS_r, BINS_theta = 360,360\n",
    "    BINS=512\n",
    "    lengthX=15.0\n",
    "    lengthY=15.0\n",
    "    vx0=-5.0\n",
    "    vy0=170.0\n",
    "    Zmin=-4.25\n",
    "    Zmax=-0.27\n",
    "    rmin, rmax = 0., 15.\n",
    "    dtheta=2*np.pi/BINS_theta\n",
    "    dr=(rmax-rmin)/BINS_r\n",
    "    thetamid=(np.arange(BINS_theta)+0.5) * dtheta - np.pi   \n",
    "    rmid=(np.arange(BINS_r)+0.5) * dr + rmin\n",
    "\n",
    "    px,py = df[\"x\"], df[\"y\"]\n",
    "    r=np.sqrt(px**2. + py**2.) \n",
    "    theta=np.arctan2(py,px)\n",
    "    h, x, y = np.histogram2d(r,theta,bins=[BINS_r,BINS_theta],range=[[rmin,rmax],[-np.pi,np.pi]])\n",
    "\n",
    "    #divide by area to get surface density\n",
    "    for i in range(0,BINS_r):\n",
    "            h[i,:]/=rmid[i]*dr*dtheta\n",
    "\n",
    "    #fit the axisymmetric surface density            \n",
    "    meanh=np.zeros(BINS_r)\n",
    "    for i in range(0,BINS_r):\n",
    "            meanh[i]=h[i,:].mean()\n",
    "    z=np.polyfit(rmid, np.log(meanh), 1)\n",
    "    Rs=-1/z[0]\n",
    "    p = np.poly1d(z)\n",
    "    print( \"Rs = \", Rs, mass )\n",
    "\n",
    "    #calculate residuals\n",
    "    for i in range(0,BINS_r):\n",
    "            #h[i,:]=(h[i,:] - np.exp(p(rmid[i]))) / np.exp(p(rmid[i]))\n",
    "            h[i,:]=(h[i,:] - h[i,:].mean()) / (h[i,:].mean())\n",
    "    Z,x,y=np.histogram2d(px/Rs,py/Rs, range=[[-lengthX/Rs,lengthX/Rs],[-lengthY/Rs,lengthY/Rs]], bins=BINS, normed=True)\n",
    "\n",
    "    Z=np.log10(Z)\n",
    "\n",
    "\n",
    "    Zmin=Z[Z>-np.inf].min()\n",
    "    Zmax=Z[Z<np.inf].max()\n",
    "    if ((Zmax==0.0) & (Zmin==0.0)):\n",
    "            Zmin=Z[Z>-np.inf].min()\n",
    "            Zmax=Z.max()\n",
    "    else:\n",
    "            Z[Z<Zmin]=Zmin\n",
    "            Z[Z>Zmax]=Zmax\n",
    "    fig = plt.figure(1, figsize=(25.0,25.0))\n",
    "\n",
    "    #left plot\n",
    "    #ax = fig.add_subplot(1,2,1,title=tname+\"  t=\"+str(round(head.time*co.UnitTime_in_Gyr*1000.0,1))+\"Myr\")\n",
    "\n",
    "    ax = fig.add_subplot(1,2,1) #,title=tname+\"  t=\"+str(round(myTime*co.UnitTime_in_Gyr*1000.0,1))+\"Myr\")\n",
    "    im=ax.imshow(Z.T, vmin=Zmin, vmax=Zmax,\n",
    "            origin='lower',interpolation='nearest',\n",
    "            extent=[-lengthX/Rs,lengthX/Rs,-lengthY/Rs,lengthY/Rs],\n",
    "            cmap=cm.get_cmap('viridis'))\n",
    "    ax.set_xlabel('x/Rs', fontsize=18, fontweight='bold')\n",
    "    ax.set_ylabel('y/Rs',fontsize=18, fontweight='bold')\n",
    "    plt.xticks(np.arange(-round(lengthX/Rs), round(lengthX/Rs), step=2), fontsize=15, fontweight='bold')\n",
    "    plt.yticks(np.arange(-round(lengthY/Rs), round(lengthY/Rs), step=2), fontsize=15, fontweight='bold')\n",
    "    plt.colorbar(im, shrink=0.35)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "record_timing": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
